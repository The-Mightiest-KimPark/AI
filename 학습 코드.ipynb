{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 특정 GPU에 7000GB 메모리만 할당하도록 제한\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=15000)])\n",
    "    except RuntimeError as e:\n",
    "    # 프로그램 시작시에 가상 장치가 설정되어야만 합니다\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 18 03:16:36 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   33C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Self-contained Python script to train YOLOv3 on your own dataset\n",
    "\"\"\"\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data\n",
    "\n",
    "\n",
    "def _main():\n",
    "    annotation_path = './train/_annotations.txt'  # path to Roboflow data annotations\n",
    "    log_dir = './logs/000/'                 # where we're storing our logs\n",
    "    classes_path = './train/_classes.txt'         # path to Roboflow class names\n",
    "    anchors_path = './model_data/yolo_anchors.txt'\n",
    "    class_names = get_classes(classes_path)\n",
    "    print(\"-------------------CLASS NAMES-------------------\")\n",
    "    print(class_names)\n",
    "    print(\"-------------------CLASS NAMES-------------------\")\n",
    "    num_classes = len(class_names)\n",
    "    anchors = get_anchors(anchors_path)\n",
    "\n",
    "    input_shape = (416,416) # multiple of 32, hw\n",
    "\n",
    "    is_tiny_version = len(anchors)==6 # default setting\n",
    "    if is_tiny_version:\n",
    "        model = create_tiny_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path='./model_data/tiny_yolo_weights.h5')\n",
    "    else:\n",
    "        model = create_model(input_shape, anchors, num_classes,\n",
    "#             freeze_body=2, weights_path='./model_data/yolo.h5') # make sure you know what you freeze\n",
    "            freeze_body=2, weights_path='./logs/000/trained_weights_stage_1.h5') # make sure you know what you freeze\n",
    "    logging = TensorBoard(log_dir=log_dir)\n",
    "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "    val_split = 0.2 # set the size of the validation set\n",
    "    with open(annotation_path) as f:\n",
    "        lines = f.readlines()\n",
    "    np.random.seed(10101)\n",
    "    np.random.shuffle(lines)\n",
    "    np.random.seed(None)\n",
    "    num_val = int(len(lines)*val_split)\n",
    "    num_train = len(lines) - num_val\n",
    "\n",
    "    # Train with frozen layers first, to get a stable loss.\n",
    "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
    "    if True:\n",
    "        model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "            # use custom yolo_loss Lambda layer.\n",
    "            'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "        batch_size = 32\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "                steps_per_epoch=max(1, num_train//batch_size),\n",
    "                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "                validation_steps=max(1, num_val//batch_size),\n",
    "                epochs=100,\n",
    "                initial_epoch=0,\n",
    "                callbacks=[logging, checkpoint])\n",
    "        model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
    "\n",
    "    # Unfreeze and continue training, to fine-tune.\n",
    "    # Train longer if the result is not good.\n",
    "    if True:\n",
    "        for i in range(len(model.layers)):\n",
    "            model.layers[i].trainable = True\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "        print('Unfreeze all of the layers.')\n",
    "\n",
    "        batch_size = 16 # note that more GPU memory is required after unfreezing the body\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=100,\n",
    "            initial_epoch=50,\n",
    "            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "        model.save_weights(log_dir + 'trained_weights_final.h5')\n",
    "\n",
    "    # Further training if needed.\n",
    "\n",
    "\n",
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "\n",
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='./model_data/yolo.h5'):\n",
    "    '''create the training model'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='./model_data/tiny_yolo_weights.h5'):\n",
    "    '''create the training model, for Tiny YOLOv3'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
    "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "\n",
    "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
    "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze the darknet body or freeze all but 2 output layers.\n",
    "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data('./train/'+annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------CLASS NAMES-------------------\n",
      "['egg', 'lemon', 'plum', 'cucumber', 'cider', 'carrot', 'squash', 'corn', 'pineapple', 'apple', 'onion', 'garlic', 'tomato', 'broccoli', 'sesame', 'eggplant', 'sweet_pumpkin', 'radish', 'cabbage', 'paprika', 'yakult', 'beer', 'cola']\n",
      "-------------------CLASS NAMES-------------------\n",
      "Create YOLOv3 model with 9 anchors and 23 classes.\n",
      "Load weights ./logs/000/trained_weights_stage_1.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3080: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Train on 1308 samples, val on 327 samples, with batch size 32.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - 104s 3s/step - loss: 23.2505 - val_loss: 23.1182\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/callbacks.py:995: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 93s 2s/step - loss: 22.6718 - val_loss: 22.0774\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 22.1414 - val_loss: 22.4922\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 73s 2s/step - loss: 22.0125 - val_loss: 21.6960\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 22.1876 - val_loss: 22.9557\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.8013 - val_loss: 21.9621\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 22.6067 - val_loss: 21.9659\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.8251 - val_loss: 22.3859\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 22.0415 - val_loss: 21.4421\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.8641 - val_loss: 22.4720\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 93s 2s/step - loss: 21.5162 - val_loss: 22.0356\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 89s 2s/step - loss: 21.7182 - val_loss: 22.5918\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 89s 2s/step - loss: 22.2487 - val_loss: 21.0435\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 22.2590 - val_loss: 23.2995\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 93s 2s/step - loss: 21.1152 - val_loss: 21.3318\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.8666 - val_loss: 22.2041\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.7824 - val_loss: 21.7649\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 86s 2s/step - loss: 21.6063 - val_loss: 21.7260\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 94s 2s/step - loss: 21.2368 - val_loss: 23.1033\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.8829 - val_loss: 21.3108\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.2220 - val_loss: 21.8713\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.7589 - val_loss: 22.1619\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 94s 2s/step - loss: 21.5609 - val_loss: 20.5231\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.5808 - val_loss: 21.7697\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.3545 - val_loss: 23.0354\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 93s 2s/step - loss: 21.6187 - val_loss: 21.0858\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 89s 2s/step - loss: 21.3459 - val_loss: 21.3813\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.5645 - val_loss: 22.4417\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.4073 - val_loss: 22.7251\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 93s 2s/step - loss: 21.6091 - val_loss: 21.8451\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.6669 - val_loss: 20.9314\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.0067 - val_loss: 22.6354\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.8932 - val_loss: 21.5725\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.3669 - val_loss: 20.9660\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.8600 - val_loss: 22.1330\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 89s 2s/step - loss: 21.1568 - val_loss: 21.6698\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 89s 2s/step - loss: 21.5794 - val_loss: 22.3825\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 95s 2s/step - loss: 21.7266 - val_loss: 22.6834\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 89s 2s/step - loss: 21.4621 - val_loss: 21.5668\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.3304 - val_loss: 22.2669\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.6969 - val_loss: 21.7173\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 89s 2s/step - loss: 21.3301 - val_loss: 21.5455\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 93s 2s/step - loss: 21.7632 - val_loss: 22.1683\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.4125 - val_loss: 21.6035\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.0522 - val_loss: 21.7960\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.1723 - val_loss: 22.1336\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.0219 - val_loss: 21.9437\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.6139 - val_loss: 21.5824\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.3002 - val_loss: 21.7139\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 93s 2s/step - loss: 21.0782 - val_loss: 21.7535\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.6106 - val_loss: 20.9866\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.5597 - val_loss: 21.9082\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.2452 - val_loss: 22.2106\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.2465 - val_loss: 21.1743\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.2471 - val_loss: 21.7220\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.0118 - val_loss: 22.3588\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.4821 - val_loss: 20.6948\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.2187 - val_loss: 21.4799\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.2888 - val_loss: 22.3067\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 93s 2s/step - loss: 21.2833 - val_loss: 20.9032\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.7753 - val_loss: 22.0056\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 89s 2s/step - loss: 21.1878 - val_loss: 21.5049\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.2324 - val_loss: 21.6888\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.6304 - val_loss: 22.0321\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 88s 2s/step - loss: 20.8601 - val_loss: 22.6209\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 94s 2s/step - loss: 20.8772 - val_loss: 21.6631\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.4876 - val_loss: 21.4435\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.4665 - val_loss: 21.0737\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 93s 2s/step - loss: 20.8641 - val_loss: 22.2214\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 88s 2s/step - loss: 21.0584 - val_loss: 21.8614\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 20.8770 - val_loss: 21.9894\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.0718 - val_loss: 20.1761\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.2661 - val_loss: 23.1466\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 89s 2s/step - loss: 21.2588 - val_loss: 21.5418\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.3273 - val_loss: 22.1897\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 20.8745 - val_loss: 22.7567\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 93s 2s/step - loss: 20.9114 - val_loss: 21.5508\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.4314 - val_loss: 21.8644\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 89s 2s/step - loss: 20.7709 - val_loss: 21.8198\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.4047 - val_loss: 21.4866\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 20.8108 - val_loss: 22.3017\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.2528 - val_loss: 21.4866\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.5446 - val_loss: 21.4590\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 20.9459 - val_loss: 21.9737\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 20.8943 - val_loss: 22.0349\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.4642 - val_loss: 21.5689\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.0361 - val_loss: 21.9027\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.3002 - val_loss: 20.8476\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.0267 - val_loss: 22.9973\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 89s 2s/step - loss: 21.1694 - val_loss: 21.3223\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.3536 - val_loss: 22.1141\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.0043 - val_loss: 21.7091\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 90s 2s/step - loss: 21.1345 - val_loss: 21.6925\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 92s 2s/step - loss: 21.3341 - val_loss: 21.8132\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.3862 - val_loss: 21.1367\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.1359 - val_loss: 21.5002\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.1768 - val_loss: 22.4473\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 89s 2s/step - loss: 21.2658 - val_loss: 21.3844\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 94s 2s/step - loss: 21.3195 - val_loss: 22.4041\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 91s 2s/step - loss: 21.3522 - val_loss: 21.2580\n",
      "Unfreeze all of the layers.\n",
      "Train on 1308 samples, val on 327 samples, with batch size 16.\n",
      "Epoch 51/100\n",
      "81/81 [==============================] - 122s 2s/step - loss: 22.7779 - val_loss: 22.0127\n",
      "Epoch 52/100\n",
      "81/81 [==============================] - 111s 1s/step - loss: 21.0515 - val_loss: 20.1115\n",
      "Epoch 53/100\n",
      "81/81 [==============================] - 108s 1s/step - loss: 20.1713 - val_loss: 21.1047\n",
      "Epoch 54/100\n",
      "81/81 [==============================] - 108s 1s/step - loss: 19.9457 - val_loss: 19.7483\n",
      "Epoch 55/100\n",
      "81/81 [==============================] - 108s 1s/step - loss: 19.2687 - val_loss: 19.2046\n",
      "Epoch 56/100\n",
      "81/81 [==============================] - 108s 1s/step - loss: 19.1730 - val_loss: 18.7314\n",
      "Epoch 57/100\n",
      "81/81 [==============================] - 108s 1s/step - loss: 18.7954 - val_loss: 18.6984\n",
      "Epoch 58/100\n",
      "81/81 [==============================] - 107s 1s/step - loss: 18.7165 - val_loss: 19.4744\n",
      "Epoch 59/100\n",
      "81/81 [==============================] - 106s 1s/step - loss: 18.5766 - val_loss: 19.3740\n",
      "Epoch 60/100\n",
      "81/81 [==============================] - 107s 1s/step - loss: 18.3705 - val_loss: 19.1130\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 61/100\n",
      "81/81 [==============================] - 110s 1s/step - loss: 17.6487 - val_loss: 18.2239\n",
      "Epoch 62/100\n",
      "81/81 [==============================] - 110s 1s/step - loss: 17.2398 - val_loss: 18.2613\n",
      "Epoch 63/100\n",
      "81/81 [==============================] - 110s 1s/step - loss: 17.1259 - val_loss: 17.3019\n",
      "Epoch 64/100\n",
      "81/81 [==============================] - 109s 1s/step - loss: 17.2161 - val_loss: 18.1362\n",
      "Epoch 65/100\n",
      "81/81 [==============================] - 109s 1s/step - loss: 17.0314 - val_loss: 18.2381\n",
      "Epoch 66/100\n",
      "81/81 [==============================] - 109s 1s/step - loss: 16.8937 - val_loss: 17.3034\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 67/100\n",
      "81/81 [==============================] - 110s 1s/step - loss: 16.7541 - val_loss: 17.8587\n",
      "Epoch 68/100\n",
      "81/81 [==============================] - 109s 1s/step - loss: 16.8807 - val_loss: 18.5431\n",
      "Epoch 69/100\n",
      "81/81 [==============================] - 109s 1s/step - loss: 17.1494 - val_loss: 17.4319\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 70/100\n",
      "81/81 [==============================] - 110s 1s/step - loss: 17.1204 - val_loss: 17.8502\n",
      "Epoch 71/100\n",
      "81/81 [==============================] - 109s 1s/step - loss: 16.8204 - val_loss: 17.6613\n",
      "Epoch 72/100\n",
      "81/81 [==============================] - 108s 1s/step - loss: 16.9098 - val_loss: 18.7406\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 73/100\n",
      "81/81 [==============================] - 108s 1s/step - loss: 16.8929 - val_loss: 17.6402\n",
      "Epoch 00073: early stopping\n"
     ]
    }
   ],
   "source": [
    "_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.3'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36] *",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
